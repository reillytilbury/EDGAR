{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3277d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add project root (parent of figures) to module search path\n",
    "import os\n",
    "os.chdir(os.path.abspath(\"..\"))  # now CWD is ai_scientist_project/\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "#  import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540b9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_program_data_new(census, reference_loss=22.02000046):\n",
    "    \"\"\"\n",
    "    Extracts program data from the NEW census arrays. These are not stored in such a stupid way as the old ones.\n",
    "    Each program is a row in a long numpy array with the following columns:\n",
    "    - 0: iteration number\n",
    "    - 1: island number\n",
    "    - 2: batch number\n",
    "    - 3: LLM name\n",
    "    - 4: loss\n",
    "    - 5: time in seconds\n",
    "    - 6: parent1 id (int)\n",
    "    - 7: parent2 id (int)\n",
    "    - 8: y_eval (float)\n",
    "     \n",
    "    Returns a dictionary with the following keys\n",
    "    - 'scores': np.ndarray of scores (exp(-(loss - reference_loss)))\n",
    "    - 'losses': np.ndarray of losses\n",
    "    - 'running_max_scores': np.ndarray of running max scores\n",
    "    - 'times': np.ndarray of times in seconds\n",
    "    - 'parent1_id': np.ndarray of parent1 ids (int)\n",
    "    - 'parent2_id': np.ndarray of parent2 ids (int)\n",
    "    - 'program_id': list of tuples representing the program ids in format (iteration, island\n",
    "    , batch)\n",
    "    - 'llm_name': np.ndarray of LLM names (str)\n",
    "    - 'innovation_indices': list of indices where innovations occurred (where the max score increases)\n",
    "    - 'generations': list of lists, where generations[k] is a list of the kth order ancestors of the winner.\n",
    "                     So generations[0] = [winner_index], generations[1] = [parent1_index, parent2_index], etc.\n",
    "    - 'y_eval': np.ndarray of y_eval values (float)\n",
    "    \"\"\"\n",
    "    # extract data from the census\n",
    "    n_programs = census.shape[0]  # number of programs\n",
    "    losses = census[:, 4]  # losses\n",
    "    times = census[:, 5]  # times in seconds\n",
    "    program_tuple_id = [tuple(census[i, :3]) for i in range(n_programs)]  # program ids as tuples (iteration, island, batch)\n",
    "    parent1_tuple_id = census[:, 6]  # parent1 ids\n",
    "    parent2_tuple_id = census[:, 7]  # parent2 ids\n",
    "    llm_name = census[:, 3]  # LLM names\n",
    "    y_eval = census[:, 8]  # y_eval values\n",
    "    n_free_params = census[:, 9]  # number of free parameters (not used in this function, but could be useful later)\n",
    "\n",
    "    # now loop through all programs with index >= 2 and find their parents\n",
    "    parent1_int_id = [-1, -1]  # initialize parent ids with -1\n",
    "    parent2_int_id = [-1, -1]  # initialize parent ids with -1\n",
    "    for i in range(2, n_programs):\n",
    "        p1_tuple_id = parent1_tuple_id[i]\n",
    "        p2_tuple_id = parent2_tuple_id[i]\n",
    "        # print(f\"Processing program {i}: {program_tuple_id[i]}, parents: {p1_tuple_id}, {p2_tuple_id}\")\n",
    "        # print(f\"p1_tuple_id.dtype: {type(p1_tuple_id)}, p2_tuple_id.dtype: {type(p2_tuple_id)}\")\n",
    "        p1_int_id = program_tuple_id.index(p1_tuple_id)\n",
    "        p2_int_id = program_tuple_id.index(p2_tuple_id)\n",
    "        # print(f\"p1_int_id: {p1_int_id}, p2_int_id: {p2_int_id}\")\n",
    "        parent1_int_id.append(p1_int_id)\n",
    "        parent2_int_id.append(p2_int_id)\n",
    "    # check everyone has 2 parents\n",
    "    assert len(parent1_int_id) == n_programs, \"parent1_int_id must have the same length as census\"\n",
    "    assert len(parent2_int_id) == n_programs, \"parent2_int_id must have the same length as census\"\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    parent1_id = np.array(parent1_int_id, dtype=int)\n",
    "    parent2_id = np.array(parent2_int_id, dtype=int)\n",
    "    llm_name = np.array(llm_name, dtype=str)\n",
    "    # subtract the start time from all times\n",
    "    times = times - np.min(times)\n",
    "    # get scores\n",
    "    losses = np.array(losses, dtype=float)\n",
    "    losses_relative = losses - reference_loss  # relative losses\n",
    "    scores = np.exp(-losses_relative)  # convert losses to scores\n",
    "    running_max_scores = np.maximum.accumulate(scores)  # running max scores\n",
    "    # look for innovations (where the max score increases) and get the indices\n",
    "    innovation_threshold = 0.01  # threshold for innovation detection\n",
    "    innovation_indices = np.where(np.diff(running_max_scores) > innovation_threshold)[0]\n",
    "    innovation_indices = innovation_indices.tolist()  # convert to list for easier manipulation\n",
    "    innovation_indices = [1] + innovation_indices  # include the first index\n",
    "\n",
    "    # build family tree of winner\n",
    "    index = np.argmax(scores)\n",
    "    generations = [[index]]\n",
    "    # now go through the most recent generation and find the parents\n",
    "    all_seed = False\n",
    "    while not all_seed:\n",
    "        current_generation = generations[-1]\n",
    "        all_seed = all([i < 2 for i in current_generation])  # check if all are seed programs\n",
    "        parent_generation = []\n",
    "        for idx in current_generation:\n",
    "            p1_idx, p2_idx = parent1_id[idx], parent2_id[idx]\n",
    "            if p1_idx >= 0:\n",
    "                parent_generation.append(p1_idx)\n",
    "            if p2_idx >= 0:\n",
    "                parent_generation.append(p2_idx)\n",
    "        parent_generation = list(set(parent_generation))\n",
    "        if len(parent_generation) == 0:\n",
    "            break\n",
    "        generations.append(parent_generation)\n",
    "\n",
    "    results_dict = {\n",
    "        'scores': scores,\n",
    "        'losses': losses,\n",
    "        'running_max_scores': running_max_scores,\n",
    "        'times': times,\n",
    "        'parent1_id': parent1_id,\n",
    "        'parent2_id': parent2_id,\n",
    "        'program_id': program_tuple_id,\n",
    "        'llm_name': llm_name,\n",
    "        'innovation_indices': innovation_indices,\n",
    "        'generations': generations,\n",
    "        'y_eval': y_eval,\n",
    "        'n_free_params': n_free_params\n",
    "    }\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5e477",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_paths = [# 'program_databases/07-15/16-22-07 (big_only)/combined/census.npy',\n",
    "                # 'program_databases/07-15/17-05-19 (big_only)/combined/census.npy',\n",
    "                # 'program_databases/07-15/17-48-16 (big_only)/combined/census.npy',\n",
    "                # 'program_databases/07-15/18-31-33 (big_only)/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-16/00-59-22 (mix)/combined/census.npy',\n",
    "                # 'program_databases/07-16/01-46-55 (mix)/combined/census.npy',\n",
    "                # 'program_databases/07-16/02-29-34 (mix)/combined/census.npy',\n",
    "                # 'program_databases/07-16/03-15-03 (mix)/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-17/07-14-37 (mix + image)/combined/census.npy',\n",
    "                # 'program_databases/07-17/08-10-17 (mix + image)/combined/census.npy',\n",
    "                # 'program_databases/07-17/09-07-26 (mix + image)/combined/census.npy',\n",
    "                # 'program_databases/07-17/10-05-55 (mix + image)/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-20/01-37-40 (image feedback)/combined/census.npy',\n",
    "                # 'program_databases/07-20/02-43-00 (image feedback)/combined/census.npy',\n",
    "                # 'program_databases/07-20/03-45-10 (image feedback)/combined/census.npy',\n",
    "                # 'program_databases/07-20/04-47-23 (image feedback)/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-16/12-46-54 (big + no_image)/combined/census.npy',\n",
    "                # 'program_databases/07-16/13-18-43 (big + no_image)/combined/census.npy',\n",
    "                # 'program_databases/07-16/13-51-51 (big + no_image)/combined/census.npy',\n",
    "                # 'program_databases/07-16/14-23-46 (big + no_image)/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-16/10-46-45 (mix + no_image)/combined/census.npy',\n",
    "                # 'program_databases/07-16/11-18-03 (mix + no_image)/combined/census.npy',\n",
    "                # 'program_databases/07-16/11-48-51 (mix + no_image)/combined/census.npy',\n",
    "                # 'program_databases/07-16/12-18-10 (mix + no_image)/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-17/11-02-49 (mix + no_image)/combined/census.npy',\n",
    "                # 'program_databases/07-17/11-42-11 (mix + no_image)/combined/census.npy',\n",
    "                # 'program_databases/07-17/12-22-36 (mix + no_image)/combined/census.npy',\n",
    "                # 'program_databases/07-17/14-55-12 (mix + no_image)/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-17/04-58-28 (no_param_est)/combined/census.npy',\n",
    "                # 'program_databases/07-17/05-31-58 (no_param_est)/combined/census.npy',\n",
    "                # 'program_databases/07-17/06-05-20 (no_param_est)/combined/census.npy',\n",
    "                # 'program_databases/07-17/06-40-16 (no_param_est)/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-17/19-02-25 (no_gradient)/combined/census.npy',\n",
    "                # 'program_databases/07-17/20-10-14 (no_gradient)/combined/census.npy',\n",
    "                # 'program_databases/07-17/21-11-44 (no_gradient)/combined/census.npy',\n",
    "                # 'program_databases/07-17/22-13-56 (no_gradient)/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-20/05-52-26 (no image)/combined/census.npy',\n",
    "                # 'program_databases/07-20/06-26-59 (no image)/combined/census.npy',\n",
    "                # 'program_databases/07-20/07-01-03 (no image)/combined/census.npy',\n",
    "                # 'program_databases/07-20/07-35-59 (no image)/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-21/15-31-23 (no_image)/combined/census.npy',\n",
    "                # 'program_databases/07-21/18-30-33 (no_image)/combined/census.npy',\n",
    "                # 'program_databases/07-21/19-33-36 (no_image)/combined/census.npy',\n",
    "                # 'program_databases/07-21/20-34-39 (no_image)/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-22/02-35-30 (no image)/combined/census.npy',\n",
    "                # 'program_databases/07-22/03-16-56 (no image)/combined/census.npy',\n",
    "                # 'program_databases/07-22/04-01-16 (no image)/combined/census.npy',\n",
    "                # 'program_databases/07-22/04-47-09 (no image)/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-22/05-31-26 (image)/combined/census.npy',\n",
    "                # 'program_databases/07-22/06-16-02 (image)/combined/census.npy',\n",
    "                # 'program_databases/07-22/07-00-37 (image)/combined/census.npy',\n",
    "                # 'program_databases/07-22/07-45-07 (image)/combined/census.npy',\n",
    "                # 'program_databases/07-23/01-00-00 (image)/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-23/03-10-12 (text)/combined/census.npy',\n",
    "                # 'program_databases/07-23/04-09-16 (text)/combined/census.npy',\n",
    "                # 'program_databases/07-23/05-08-08 (text)/combined/census.npy',\n",
    "                # 'program_databases/07-23/06-07-12 (text)/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-22/23-18-55 (image)/combined/census.npy',\n",
    "                # 'program_databases/07-23/00-21-26 (image)/combined/census.npy',\n",
    "                # 'program_databases/07-23/01-16-39 (image)/combined/census.npy',\n",
    "                # 'program_databases/07-23/02-14-04 (image)/combined/census.npy',\n",
    "\n",
    "                'program_databases/07-30/15-16-32/combined/census.npy',\n",
    "                'program_databases/07-30/16-11-02/combined/census.npy',\n",
    "                'program_databases/07-30/17-01-31/combined/census.npy',\n",
    "\n",
    "                'program_databases/07-30/17-52-59/combined/census.npy',\n",
    "                'program_databases/07-30/18-44-20/combined/census.npy',\n",
    "                'program_databases/07-30/19-31-37/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-31/03-14-29/combined/census.npy',\n",
    "                # 'program_databases/07-31/03-52-27/combined/census.npy',\n",
    "                # 'program_databases/07-31/04-31-51/combined/census.npy',\n",
    "                # 'program_databases/07-31/05-08-24/combined/census.npy',\n",
    "\n",
    "                # 'program_databases/07-31/05-49-09/combined/census.npy',\n",
    "                # 'program_databases/07-31/06-20-58/combined/census.npy',\n",
    "                # 'program_databases/07-31/06-55-12/combined/census.npy',\n",
    "                # 'program_databases/07-31/07-37-03/combined/census.npy',\n",
    "\n",
    "                ]\n",
    "results_list = []\n",
    "for i, path in enumerate(census_paths):\n",
    "    census = np.load(path, allow_pickle=True)\n",
    "    print(f\"Processing {path}...\")\n",
    "    results = extract_program_data_new(census,reference_loss=28.85)\n",
    "    results_list.append(results)\n",
    "\n",
    "times = [results['times'] for results in results_list]\n",
    "scores = [results['scores'] for results in results_list]\n",
    "running_max_scores = [results['running_max_scores'] for results in results_list]\n",
    "generations = [np.array([results['program_id'][i][0] for i in range(len(results['program_id']))]) for results in results_list]\n",
    "\n",
    "# # calculate losses at sampled times\n",
    "# t_max = max([np.max(t) for t in times])  # find the maximum time across all runs\n",
    "# t_samples = np.linspace(0, t_max, n_time_samples, endpoint=False)\n",
    "# # for each t_sample and each run, find the closest time and get the max score at that time\n",
    "# max_scores_sampled = np.zeros((len(running_max_scores), len(t_samples)))\n",
    "# for i, running_max_score in enumerate(running_max_scores):\n",
    "#     for j, t_sample in enumerate(t_samples):\n",
    "#         # find the closest time to t_sample\n",
    "#         closest_time_idx = np.argmin(np.abs(times[i] - t_sample))\n",
    "#         max_scores_sampled[i, j] = running_max_score[closest_time_idx]\n",
    "\n",
    "# # calculate mean and std for each group\n",
    "# mean_scores = []\n",
    "# std_scores = []\n",
    "# for i, group in enumerate(group_indices):\n",
    "#     group_scores = max_scores_sampled[group, :]\n",
    "#     mean_scores.append(np.mean(group_scores, axis=0))\n",
    "#     std_scores.append(np.std(group_scores, axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c2fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_no = 4\n",
    "y_eval = results_list[simulation_no]['y_eval']\n",
    "scores = results_list[simulation_no]['scores']\n",
    "y_eval = np.array([np.array(y_eval[i]) for i in range(len(y_eval))])\n",
    "y_eval = y_eval.reshape(y_eval.shape[0], -1)  # flatten the last two dimensions\n",
    "# nan -> num\n",
    "y_eval = np.nan_to_num(y_eval, nan=0.0)  # replace NaN with 0\n",
    "# look at the first few cells\n",
    "y_eval = y_eval[:, :100 * 20]\n",
    "\n",
    "colours = ['blue', 'orange', 'green', 'red']\n",
    "program_indices = [0, 1]\n",
    "score_argmax = np.argmax(results_list[simulation_no]['scores'])\n",
    "program_indices += [score_argmax]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "n_cells_view = 3  # number of cells to view\n",
    "for i, program_index in enumerate(program_indices):\n",
    "    plt.plot(y_eval[program_index, :n_cells_view * 100], \n",
    "             label=f'Program {program_index + 1}', \n",
    "             color=colours[i], \n",
    "             linewidth=2.0, \n",
    "             alpha=0.8)\n",
    "# add dashed vertical lines at the start of each cell\n",
    "for i in range(1, n_cells_view + 1):\n",
    "    plt.axvline(x=i * 100, color='grey', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "plt.xlabel('theta')\n",
    "plt.ylabel('prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "# perform nonlinear dimensionality reduction on the y_eval data\n",
    "umap_model = umap.UMAP(n_components=2, n_neighbors=10, min_dist=1, metric='euclidean')\n",
    "y_eval_embedded = umap_model.fit_transform(y_eval)\n",
    "# from sklearn.manifold import TSNE\n",
    "# tsne_model = TSNE(n_components=2, random_state=42, perplexity=50)\n",
    "# y_eval_embedded = tsne_model.fit_transform(y_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615eb3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an image of the t-SNE embedding, by interpolating the points\n",
    "# center so both dims have mean 0\n",
    "y_eval_embedded = y_eval_embedded - np.mean(y_eval_embedded, axis=0)\n",
    "# scale so min and max are -1 and 1\n",
    "y_eval_embedded = y_eval_embedded / np.max(np.abs(y_eval_embedded), axis=0)\n",
    "sigma = 0.07\n",
    "x = np.linspace(-1.0, 0.75, 100)  # x-axis range for the t-SNE embedding\n",
    "y = np.linspace(-1.0, 1.0, 100)  # y-axis range for the t-SNE embedding\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.zeros(X.shape)\n",
    "D = np.zeros(X.shape)  # Denominator for normalization\n",
    "const = 1e-2\n",
    "\n",
    "for i in range(len(y_eval_embedded)):\n",
    "    xi = y_eval_embedded[i, 0]\n",
    "    yi = y_eval_embedded[i, 1]\n",
    "    zi = scores[i]\n",
    "    # Interpolate the score onto the grid\n",
    "    Z += zi * np.exp(-((X - xi) ** 2 + (Y - yi) ** 2) / (2 * sigma ** 2))\n",
    "    D += const + np.exp(-((X - xi) ** 2 + (Y - yi) ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "Z = Z / D  # Normalize by the denominator to get the average score at each point\n",
    "\n",
    "surf = go.Surface(x=X, y=Y, z=Z,\n",
    "                  colorscale='Viridis', showscale=False,\n",
    "                  name='Smoothed surface')\n",
    "\n",
    "# ---------- helper that returns Z at any (x, y) -------------------\n",
    "Ny, Nx = Z.shape\n",
    "dx, dy = x[1] - x[0], y[1] - y[0]\n",
    "ix_scale, iy_scale = 1 / dx, 1 / dy\n",
    "\n",
    "def surface_z(xp, yp):\n",
    "    ix = np.clip(((xp - x[0]) * ix_scale).round().astype(int), 0, Nx - 1)\n",
    "    iy = np.clip(((yp - y[0]) * iy_scale).round().astype(int), 0, Ny - 1)\n",
    "    return Z[iy, ix]                # note: row (y) index first!\n",
    "\n",
    "# ---------- 1. Ancestors of the best program ----------------------------\n",
    "best_program_index = np.argmax(scores)\n",
    "generations = results_list[simulation_no]['generations']\n",
    "ancestor_indices = [ancestor for generation in generations for ancestor in generation]\n",
    "\n",
    "z_ancestors = surface_z(y_eval_embedded[ancestor_indices, 0],  # ancestors' smoothed scores\n",
    "                        y_eval_embedded[ancestor_indices, 1]) + 0.02\n",
    "\n",
    "all_pts = go.Scatter3d(\n",
    "    x=y_eval_embedded[ancestor_indices, 0],\n",
    "    y=y_eval_embedded[ancestor_indices, 1],\n",
    "    z=z_ancestors,\n",
    "    mode='markers',\n",
    "    marker=dict(size=4,\n",
    "                # color=scores[ancestor_indices],  # colour matches surface height\n",
    "                color='black',  # all black\n",
    "                symbol='circle',\n",
    "                # colorscale='Viridis',\n",
    "                opacity=0.9,\n",
    "                showscale=False),\n",
    "    name='Ancestors of Best Program'\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- 2. Seed programmes (just two special points) ----------\n",
    "seed_idx = [0, 1]\n",
    "z_seed   = surface_z(y_eval_embedded[seed_idx, 0],\n",
    "                     y_eval_embedded[seed_idx, 1]) + 0.02\n",
    "\n",
    "seed_pts = go.Scatter3d(\n",
    "    x=y_eval_embedded[seed_idx, 0],\n",
    "    y=y_eval_embedded[seed_idx, 1],\n",
    "    z=z_seed,\n",
    "    mode='markers',\n",
    "    marker=dict(size=8, color='red', symbol='cross'),\n",
    "    name='Seed programmes'\n",
    ")\n",
    "\n",
    "# ---------- 3. Assemble and show ----------------------------------\n",
    "fig = go.Figure(data=[surf, all_pts, seed_pts])\n",
    "for i in range(len(ancestor_indices) - 1):\n",
    "    p1, p2 = ancestor_indices[i], ancestor_indices[i + 1]\n",
    "    if p1 < 0 or p2 < 0:\n",
    "        continue                       # skip undefined parents\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=y_eval_embedded[[p1, p2], 0],\n",
    "        y=y_eval_embedded[[p1, p2], 1],\n",
    "        z=z_ancestors[[i,   i+1]],\n",
    "        mode='lines',\n",
    "        line=dict(color='black', width=1.5, dash='dash'),\n",
    "        showlegend=False\n",
    "    ))\n",
    "    \n",
    "fig.update_layout(\n",
    "    width = 1000,        # px\n",
    "    height = 700,        # px\n",
    "    scene = dict(\n",
    "        xaxis_title='t‑SNE‑1',\n",
    "        yaxis_title='t‑SNE‑2',\n",
    "        zaxis_title='Smoothed score',\n",
    "        camera=dict(eye=dict(x=1.3, y=1.3, z=0.9))\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, t=40, b=0)\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
